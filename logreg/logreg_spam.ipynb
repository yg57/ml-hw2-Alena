{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using regularized logistic regression to classify email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import utils\n",
    "from sklearn import linear_model\n",
    "#import sklearn.cross_validation\n",
    "from sklearn import model_selection\n",
    "#from sklearn.cross_validation import KFold\n",
    "import scipy.io\n",
    "\n",
    "# This is a bit of magic to make matplotlib figures appear inline in the notebook\n",
    "# rather than in a new window.\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# Some more magic so that the notebook will reload external python modules;\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 Penalty experiments -----------\n",
      "best_lambda = 0.100\n",
      "Coefficients = [-4.86040334] [[-2.74989021e-02 -2.25078145e-01  1.21933342e-01  2.27519296e+00\n",
      "   2.70510908e-01  2.32902366e-01  9.28075879e-01  2.95203238e-01\n",
      "   1.62391465e-01  6.78236056e-02 -8.32285561e-02 -1.60331906e-01\n",
      "  -4.73192480e-02  1.09035781e-02  1.88419472e-01  8.20190621e-01\n",
      "   5.10133424e-01  3.99166951e-02  2.67707779e-01  3.47720628e-01\n",
      "   2.60450591e-01  3.63304053e-01  7.24359842e-01  1.96754553e-01\n",
      "  -3.15921102e+00 -4.03826233e-01 -1.25620964e+01 -6.07598298e-02\n",
      "  -1.55647644e+00 -5.63375367e-02 -3.19234250e-02  4.07136076e-01\n",
      "  -3.68546152e-01 -1.39395310e+00 -5.81551120e-01  4.43928532e-01\n",
      "   4.22303189e-02 -1.56981219e-01 -4.55678098e-01 -1.02371553e-01\n",
      "  -3.52786604e+00 -1.73940286e+00 -4.36522978e-01 -1.06146498e+00\n",
      "  -9.18569211e-01 -1.75180743e+00 -1.67476526e-01 -9.53309298e-01\n",
      "  -3.65592304e-01 -1.36376560e-01 -6.58582617e-02  2.06565615e-01\n",
      "   1.70665682e+00  1.22652148e+00 -3.33950136e-01  1.55492810e+00\n",
      "   3.69875665e-01]]\n",
      "Accuracy on set aside test set for std = 0.9290\n",
      "best_lambda = 0.600\n",
      "Coefficients = [-4.60944873] [[-0.45145938 -0.28466537 -0.06328196  0.68295767  1.2105318   0.91504907\n",
      "   2.83046111  1.4367732   0.24145409  0.35775328 -0.38641852 -0.48142515\n",
      "  -0.6958679   0.37457132  0.64885442  1.53956261  1.38118555  0.07197865\n",
      "   0.37641928  0.63501784  0.52275122  0.38563629  2.00138227  1.50817679\n",
      "  -3.14060675 -0.66617654 -4.90648358 -0.03260854 -1.28886267 -0.1574585\n",
      "  -0.63899152 -0.30228438 -1.00990367 -0.42568322 -1.08721351  1.28431531\n",
      "  -0.90559168 -0.35285798 -1.12971325 -0.62588118 -1.40336877 -2.44122956\n",
      "  -1.55652936 -1.94778251 -1.1311298  -2.79990882 -0.75122348 -2.11601351\n",
      "  -1.68510376 -0.66773137 -0.69125394  2.06913595  4.21977884  0.76309151\n",
      "   0.70345809  0.17008692  0.43018797]]\n",
      "Accuracy on set aside test set for logt = 0.9434\n",
      "best_lambda = 1.100\n",
      "Coefficients = [-1.83742965] [[-1.91463199e-01 -1.66872957e-01 -3.93802023e-01  2.39462779e-01\n",
      "   9.83292893e-01  1.75311414e-01  2.12183419e+00  7.92547596e-01\n",
      "   1.94566580e-01  3.34388296e-01 -2.90824615e-01 -4.20297341e-01\n",
      "  -9.06380381e-01  2.56299856e-01  5.15189474e-01  1.47014136e+00\n",
      "   8.76696476e-01 -8.32760956e-02  2.41264180e-01  5.01801273e-01\n",
      "   7.37046896e-01  1.15518007e+00  9.11195183e-01  1.36902984e+00\n",
      "  -2.35248856e+00 -4.17190306e-01 -3.79772643e+00  6.88337611e-01\n",
      "  -6.07237597e-01 -1.61622832e-01 -9.24671804e-01 -6.04558749e-01\n",
      "  -6.91161481e-01 -3.85638229e-02 -6.71440136e-01  3.52732370e-01\n",
      "  -1.05408408e+00  5.28551480e-01 -7.65306731e-01 -2.46067578e-01\n",
      "  -1.27643951e+00 -1.90613122e+00 -7.90184279e-01 -1.57619158e+00\n",
      "  -7.64312034e-01 -2.22366816e+00 -8.34144234e-02 -1.39371572e+00\n",
      "  -3.06993897e-01  2.00231957e-01 -1.70968577e-01  1.20762876e+00\n",
      "   1.45771409e+00  3.79908695e-02  5.31813721e-04  5.31813721e-04\n",
      "   5.31813721e-04]]\n",
      "Accuracy on set aside test set for bin = 0.9277\n",
      "L1 Penalty experiments -----------\n",
      "best_lambda = 4.600\n",
      "Coefficients = [-1.58276232] [[-0.01060239 -0.15867145  0.12268243  0.20878053  0.24912531  0.17684124\n",
      "   0.91090584  0.28979823  0.13940813  0.04855514 -0.02290589 -0.13978322\n",
      "  -0.00712245  0.0091679   0.15421848  0.75696356  0.46002216  0.07047221\n",
      "   0.25409548  0.19624542  0.24316229  0.3468108   0.72782859  0.23431618\n",
      "  -2.33581104 -0.35722107 -3.14310362 -0.01077737 -0.3692761   0.\n",
      "   0.          0.         -0.32741922  0.         -0.06118607  0.24263428\n",
      "   0.         -0.11596534 -0.3110982  -0.04389535 -0.23880378 -0.7937734\n",
      "  -0.19043444 -0.56444565 -0.73332286 -1.17789161 -0.0854992  -0.51299394\n",
      "  -0.25650503 -0.13383445 -0.05677925  0.21845096  1.64890215  0.22183307\n",
      "   0.          0.64927287  0.33251844]]\n",
      "Accuracy on set aside test set for std = 0.9219\n",
      "best_lambda = 1.600\n",
      "Coefficients = [-4.46335947] [[-0.34341339 -0.09563527  0.          0.12937237  1.18467483  0.69053394\n",
      "   2.91323168  1.37690721  0.          0.2951142   0.         -0.48057687\n",
      "  -0.3279095   0.10729634  0.          1.49526534  1.34897077  0.\n",
      "   0.3549808   0.19678165  0.4944073   0.34754585  1.78475642  1.32948102\n",
      "  -3.49778448 -0.2695411  -7.49441773  0.         -0.41742639  0.\n",
      "   0.          0.         -0.7913237   0.         -0.23869567  0.87199094\n",
      "  -0.77445927  0.         -0.88303011  0.         -0.30394023 -2.35516419\n",
      "  -0.69467046 -1.66125088 -1.13794305 -2.98262047  0.         -1.90111904\n",
      "  -1.24513461 -0.30321383  0.          2.0147341   5.36666864  0.\n",
      "   0.63688166  0.20186615  0.3881131 ]]\n",
      "Accuracy on set aside test set for logt = 0.9440\n",
      "best_lambda = 3.600\n",
      "Coefficients = [-0.93699002] [[ 0.          0.         -0.19331624  0.          0.86571337  0.\n",
      "   2.02949756  0.63300896  0.02664145  0.21273434  0.         -0.42101476\n",
      "  -0.6813059   0.          0.          1.3158541   0.76576955  0.\n",
      "   0.10561756  0.12297196  0.6359092   0.73062423  0.62194242  1.18363865\n",
      "  -2.42324995 -0.12629462 -3.73134692  0.          0.          0.\n",
      "   0.          0.         -0.28805608  0.         -0.21924598  0.\n",
      "  -1.01572828  0.         -0.40492018  0.         -0.1152749  -1.69454902\n",
      "  -0.03922492 -1.1099471  -0.6871938  -2.21936867  0.         -1.02561495\n",
      "  -0.12536076  0.07427094  0.          1.15036446  1.49973704  0.\n",
      "  -0.476415   -0.02541465 -0.22693992]]\n",
      "Accuracy on set aside test set for bin = 0.9258\n"
     ]
    }
   ],
   "source": [
    "# No modifications in this cell\n",
    "# complete the functions in utils.py; then run the cell\n",
    "\n",
    "Xtrain,Xtest,ytrain,ytest = utils.load_spam_data()\n",
    "\n",
    "# Preprocess the data \n",
    "\n",
    "Xtrain_std,mu,sigma = utils.std_features(Xtrain)\n",
    "Xtrain_logt = utils.log_features(Xtrain)\n",
    "Xtrain_bin = utils.bin_features(Xtrain)\n",
    "\n",
    "Xtest_std = (Xtest - mu)/sigma\n",
    "Xtest_logt = utils.log_features(Xtest)\n",
    "Xtest_bin = utils.bin_features(Xtest)\n",
    "\n",
    "# find good lambda by cross validation for these three sets\n",
    "\n",
    "def run_dataset(X,ytrain,Xt,ytest,typea,penalty):\n",
    "\n",
    "    best_lambda = utils.select_lambda_crossval(X,ytrain,0.1,5.1,0.5,penalty)\n",
    "    print(\"best_lambda = %.3f\" %best_lambda)\n",
    "\n",
    "    # train a classifier on best_lambda and run it\n",
    "    if penalty == \"l2\":\n",
    "        lreg = linear_model.LogisticRegression(penalty=penalty,C=1.0/best_lambda, solver='lbfgs',fit_intercept=True, max_iter = 1000)\n",
    "    else:\n",
    "        lreg = linear_model.LogisticRegression(penalty=penalty,C=1.0/best_lambda, solver='liblinear',fit_intercept=True, max_iter = 1000)\n",
    "    lreg.fit(X,ytrain)\n",
    "    print(\"Coefficients = %s\" %lreg.intercept_,lreg.coef_)\n",
    "    predy = lreg.predict(Xt)\n",
    "    print(\"Accuracy on set aside test set for %s = %.4f\" %(typea, np.mean(predy==ytest)))\n",
    "\n",
    "print(\"L2 Penalty experiments -----------\")\n",
    "run_dataset(Xtrain_std,ytrain,Xtest_std,ytest,\"std\",\"l2\")\n",
    "run_dataset(Xtrain_logt,ytrain,Xtest_logt,ytest,\"logt\",\"l2\")\n",
    "run_dataset(Xtrain_bin,ytrain,Xtest_bin,ytest,\"bin\",\"l2\")\n",
    "\n",
    "print(\"L1 Penalty experiments -----------\")\n",
    "run_dataset(Xtrain_std,ytrain,Xtest_std,ytest,\"std\",\"l1\")\n",
    "run_dataset(Xtrain_logt,ytrain,Xtest_logt,ytest,\"logt\",\"l1\")\n",
    "run_dataset(Xtrain_bin,ytrain,Xtest_bin,ytest,\"bin\",\"l1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
